{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 로지스틱 회귀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# 버전 2가 1을 흉내낸것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[2, 3],[4, 3],[6, 4],[8, 6],[10, 7],[12, 8],[14, 9]])\n",
    "y_data = np.array([0, 0, 0, 1, 1, 1, 1]).reshape(7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2) (7, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 값을 플레이스 홀더에 저장\n",
    "X = tf.placeholder(tf.float64, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float64, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웨이트 a와 바이어스 b의 값을 임의로 정함\n",
    "w = tf.Variable(tf.random_uniform([2,1], dtype=tf.float64))\n",
    "# [2,1] 의미: 들어오는 값은 2개 나가는 값은 1개\n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 시그모이드 함수의 방정식을 세움\n",
    "yhat = tf.sigmoid(tf.matmul(X, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차 구하는 함수\n",
    "loss = -tf.reduce_mean(Y * tf.log(yhat) + (1 - Y) * tf.log(1 - yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 값\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차를 최소로 하는 값 찾기\n",
    "# 경사 하강법에 있는 최적화를 쓰겠다\n",
    "# 평균값을 최소화하는 경우로 학습하겠다\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y값이 0.5보다 크면 실수값으로 (1아니면 0으로) 받겠다\n",
    "predicted = tf.cast(yhat > 0.5, dtype = tf.float64)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=300, w1=0.8678, w2=-0.6498, b=-2.3101, loss=0.2745\n",
      "step=600, w1=0.8553, w2=-0.3569, b=-3.8012, loss=0.1963\n",
      "step=900, w1=0.7588, w2=-0.0174, b=-4.8811, loss=0.1530\n",
      "step=1200, w1=0.6506, w2=0.2977, b=-5.7345, loss=0.1249\n",
      "step=1500, w1=0.5482, w2=0.5774, b=-6.4414, loss=0.1052\n",
      "step=1800, w1=0.4560, w2=0.8235, b=-7.0450, loss=0.0907\n",
      "step=2100, w1=0.3744, w2=1.0402, b=-7.5720, loss=0.0797\n",
      "step=2400, w1=0.3025, w2=1.2321, b=-8.0397, loss=0.0710\n",
      "step=2700, w1=0.2389, w2=1.4033, b=-8.4602, loss=0.0639\n",
      "step=3000, w1=0.1825, w2=1.5570, b=-8.8421, loss=0.0582\n",
      "공부한 시간: 7, 과외 수업 횟수: 6\n",
      "합격할 가능성:  99.98 %\n"
     ]
    }
   ],
   "source": [
    "# 학습(3000번 300번 단위로)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(3001):\n",
    "        w_, b_, loss_, _ = sess.run([w, b, loss, gradient_decent], feed_dict={X: x_data, Y: y_data})\n",
    "        if(i + 1) % 300 ==0:\n",
    "            print(\"step=%d, w1=%.4f, w2=%.4f, b=%.4f, loss=%.4f\" % \n",
    "                  (i + 1, w_[0], w_[1], b_, loss_))\n",
    "            \n",
    "    new_x = np.array([7, 6.]).reshape(1,2) # [7,6]은 각각 공부한 시간과 과외 수업 횟수\n",
    "    new_y = sess.run(y, feed_dict={X:new_x})\n",
    "    \n",
    "    print(\"공부한 시간: %d, 과외 수업 횟수: %d\" %(new_x[:,0], new_x[:,1]))\n",
    "    print(\"합격할 가능성: %6.2f %%\" %(new_y*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=3000, w1=0.1825, w2=1.5570, b=-8.8421, loss=0.0582\n",
      "step=6000, w1=-0.1601, w2=2.5526, b=-11.4656, loss=0.0306\n",
      "step=9000, w1=-0.3336, w2=3.1119, b=-13.0651, loss=0.0208\n",
      "step=12000, w1=-0.4477, w2=3.5005, b=-14.2193, loss=0.0158\n",
      "step=15000, w1=-0.5324, w2=3.7987, b=-15.1232, loss=0.0127\n",
      "step=18000, w1=-0.5998, w2=4.0408, b=-15.8664, loss=0.0107\n",
      "step=21000, w1=-0.6557, w2=4.2448, b=-16.4977, loss=0.0092\n",
      "step=24000, w1=-0.7036, w2=4.4211, b=-17.0466, loss=0.0081\n",
      "step=27000, w1=-0.7454, w2=4.5763, b=-17.5321, loss=0.0072\n",
      "step=30000, w1=-0.7825, w2=4.7150, b=-17.9675, loss=0.0065\n",
      "step=33000, w1=-0.8158, w2=4.8403, b=-18.3621, loss=0.0059\n",
      "step=36000, w1=-0.8461, w2=4.9547, b=-18.7231, loss=0.0054\n",
      "step=39000, w1=-0.8739, w2=5.0598, b=-19.0557, loss=0.0050\n",
      "step=42000, w1=-0.8995, w2=5.1572, b=-19.3640, loss=0.0047\n",
      "step=45000, w1=-0.9232, w2=5.2478, b=-19.6514, loss=0.0044\n",
      "step=48000, w1=-0.9454, w2=5.3325, b=-19.9206, loss=0.0041\n",
      "step=51000, w1=-0.9662, w2=5.4121, b=-20.1737, loss=0.0039\n",
      "step=54000, w1=-0.9857, w2=5.4871, b=-20.4126, loss=0.0037\n",
      "step=57000, w1=-1.0042, w2=5.5581, b=-20.6388, loss=0.0035\n",
      "step=60000, w1=-1.0217, w2=5.6254, b=-20.8535, loss=0.0033\n",
      "공부한 시간: 7, 과외 수업 횟수: 6\n",
      "합격할 가능성:  99.98 %\n"
     ]
    }
   ],
   "source": [
    "# 학습(60000만번 3000번 단위로)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(60001):\n",
    "        w_, b_, loss_, _ = sess.run([w, b, loss, gradient_decent], feed_dict={X: x_data, Y: y_data})\n",
    "        if(i + 1) % 3000 ==0:\n",
    "            print(\"step=%d, w1=%.4f, w2=%.4f, b=%.4f, loss=%.4f\" % \n",
    "                  (i + 1, w_[0], w_[1], b_, loss_))\n",
    "            \n",
    "    new_x = np.array([7, 6.]).reshape(1,2) # [7,6]은 각각 공부한 시간과 과외 수업 횟수\n",
    "    new_y = sess.run(y, feed_dict={X:new_x})\n",
    "    \n",
    "    print(\"공부한 시간: %d, 과외 수업 횟수: %d\" %(new_x[:,0], new_x[:,1]))\n",
    "    print(\"합격할 가능성: %6.2f %%\" %(new_y*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 계산으로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = np.array([7,6.]).reshape(1,2)\n",
    "m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = np.array([0.1779, 1.5675]).reshape(2,1)\n",
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.6503]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8565344988956533\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(10.6503 - 8.8635))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
