{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2, os, random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dogs-vs-cats/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW, COL = 96, 96\n",
    "\n",
    "dogs, cats = [], []\n",
    "y_dogs, y_cats = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dogs():\n",
    "    print('Loading all dog images\\n')\n",
    "    dog_path = os.path.join(path, 'dog*')\n",
    "    for dog_img in glob(dog_path):\n",
    "        dog = cv2.imread(dog_img)\n",
    "        dog = cv2.cvtColor(dog, cv2.COLOR_BGR2GRAY)\n",
    "        dog = cv2.resize(dog, (ROW, COL))\n",
    "        dog = image.img_to_array(dog)\n",
    "        dogs.append(dog)\n",
    "    print('All dog images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cats():\n",
    "    print('Loading all dog images\\n')\n",
    "    cat_path = os.path.join(path, 'cat*')\n",
    "    for cat_img in glob(cat_path):\n",
    "        cat = cv2.imread(cat_img)\n",
    "        cat = cv2.cvtColor(cat, cv2.COLOR_BGR2GRAY)\n",
    "        cat = cv2.resize(cat, (ROW, COL))\n",
    "        cat = image.img_to_array(cat)\n",
    "        cats.append(cat)\n",
    "    print('All cat images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dog images\n",
      "\n",
      "All dog images loaded\n"
     ]
    }
   ],
   "source": [
    "load_dogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dog images\n",
      "\n",
      "All cat images loaded\n"
     ]
    }
   ],
   "source": [
    "load_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['dog', 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dogs():\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        img = image.array_to_imgay_to_img(random.choice(dogs))\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.title('Supposed to be a {}'.format(classes[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cats():\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(5):\n",
    "        plt.subplot(1,5, i+1)\n",
    "        img = image.array_to_img(random.choice(cats))\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.title('Supposed to be a {}'.format(classes[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dogs = [1 for item in enumerate(dogs)]\n",
    "y_cats = [0 for item in enumerate(cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = np.asarray(dogs).astype('float32')/255.0\n",
    "cats = np.asarray(cats).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_train = dogs[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = cats[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_test = dogs[10000:12500]\n",
    "cat_test = cats[10000:12500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 96, 96, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_dogs = np.asarray(y_dogs[:10000]).astype('int32')\n",
    "y_cats = np.asarray(y_cats[:10000]).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((dog_train, cat_train), axis=0)\n",
    "X_test =  np.concatenate((dog_test, cat_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_dogs, y_cats), axis=0)\n",
    "y_test =  np.concatenate((y_dogs, y_cats), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000,), (20000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 18,940,898\n",
      "Trainable params: 18,940,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', input_shape=(ROW, COL, 1), activation='relu'), #padding 사이즈 똑같이\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)), # 사이즈가 반으로 줄어듦(48x48)\n",
    "    Dropout(.25),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer =Adam(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = 'model/dogs_vs_cats_full-cnn-{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.6379 - accuracy: 0.6416\n",
      "Epoch 00001: val_loss improved from inf to 0.92913, saving model to model/dogs_vs_cats_full-cnn-01-0.9291.hdf5\n",
      "16000/16000 [==============================] - 411s 26ms/sample - loss: 0.6377 - accuracy: 0.6417 - val_loss: 0.9291 - val_accuracy: 0.4475\n",
      "Epoch 2/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.5181 - accuracy: 0.7456\n",
      "Epoch 00002: val_loss improved from 0.92913 to 0.75607, saving model to model/dogs_vs_cats_full-cnn-02-0.7561.hdf5\n",
      "16000/16000 [==============================] - 256s 16ms/sample - loss: 0.5179 - accuracy: 0.7456 - val_loss: 0.7561 - val_accuracy: 0.5450\n",
      "Epoch 3/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.7968\n",
      "Epoch 00003: val_loss improved from 0.75607 to 0.51616, saving model to model/dogs_vs_cats_full-cnn-03-0.5162.hdf5\n",
      "16000/16000 [==============================] - 251s 16ms/sample - loss: 0.4378 - accuracy: 0.7971 - val_loss: 0.5162 - val_accuracy: 0.7495\n",
      "Epoch 4/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.3925 - accuracy: 0.8214\n",
      "Epoch 00004: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 249s 16ms/sample - loss: 0.3928 - accuracy: 0.8212 - val_loss: 0.7413 - val_accuracy: 0.6270\n",
      "Epoch 5/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.3474 - accuracy: 0.8504\n",
      "Epoch 00005: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 248s 16ms/sample - loss: 0.3475 - accuracy: 0.8504 - val_loss: 1.0354 - val_accuracy: 0.5008\n",
      "Epoch 6/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.2969 - accuracy: 0.8733\n",
      "Epoch 00006: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 248s 15ms/sample - loss: 0.2967 - accuracy: 0.8734 - val_loss: 0.6885 - val_accuracy: 0.6902\n",
      "Epoch 7/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.8982\n",
      "Epoch 00007: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 248s 16ms/sample - loss: 0.2417 - accuracy: 0.8982 - val_loss: 0.7137 - val_accuracy: 0.7155\n",
      "Epoch 8/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.1949 - accuracy: 0.9226\n",
      "Epoch 00008: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 248s 16ms/sample - loss: 0.1947 - accuracy: 0.9227 - val_loss: 0.5491 - val_accuracy: 0.7655\n",
      "Epoch 9/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9354\n",
      "Epoch 00009: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 248s 16ms/sample - loss: 0.1646 - accuracy: 0.9353 - val_loss: 1.2174 - val_accuracy: 0.6365\n",
      "Epoch 10/40\n",
      "15968/16000 [============================>.] - ETA: 6s - loss: 0.1338 - accuracy: 0.9508 \n",
      "Epoch 00010: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 3254s 203ms/sample - loss: 0.1338 - accuracy: 0.9507 - val_loss: 0.7742 - val_accuracy: 0.7585\n",
      "Epoch 11/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.9597\n",
      "Epoch 00011: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 259s 16ms/sample - loss: 0.1074 - accuracy: 0.9597 - val_loss: 1.3875 - val_accuracy: 0.6263\n",
      "Epoch 12/40\n",
      "15968/16000 [============================>.] - ETA: 0s - loss: 0.1003 - accuracy: 0.9622\n",
      "Epoch 00012: val_loss did not improve from 0.51616\n",
      "16000/16000 [==============================] - 350s 22ms/sample - loss: 0.1001 - accuracy: 0.9623 - val_loss: 1.0958 - val_accuracy: 0.6998\n",
      "Epoch 13/40\n",
      " 3456/16000 [=====>........................] - ETA: 5:06 - loss: 0.0734 - accuracy: 0.9751"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs =40, validation_split=0.2, callbacks=[checkpointer, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model/.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('MODEL ACCURACY: %.5f' % scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
